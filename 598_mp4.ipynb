{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamMcneil/data-management-project/blob/main/598_mp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHOxFKTMPPFV",
        "outputId": "850d722b-1337-498d-b25b-6040c5955c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: scann in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from scann) (5.29.4)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install h5py faiss-cpu requests scann\n",
        "import faiss\n",
        "import h5py\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import requests\n",
        "import scann\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qa_yzdxePPFW"
      },
      "outputs": [],
      "source": [
        "SIFT1M_URL = \"http://ann-benchmarks.com/sift-128-euclidean.hdf5\"\n",
        "SIFT1M_FILENAME = \"sift-128-euclidean.hdf5\"\n",
        "\n",
        "GLOVE_URL = \"http://ann-benchmarks.com/glove-100-angular.hdf5\"\n",
        "GLOVE_FILENAME = \"glove-100-angular.hdf5\"\n",
        "\n",
        "def download_sift1m(url, file_name):\n",
        "    \"\"\"Downloads the SIFT1M dataset if it's not already present.\"\"\"\n",
        "    if not os.path.exists(file_name):\n",
        "        print(\"Downloading \", file_name, \"dataset...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        with open(file_name, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(\"Download complete.\")\n",
        "    else:\n",
        "        print(\"SIFT1M dataset already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "94SAPcExPPFW"
      },
      "outputs": [],
      "source": [
        "def load_sift1m(file_name):\n",
        "    with h5py.File(file_name, \"r\") as f:\n",
        "        print(f)\n",
        "        train_data = np.array(f[\"train\"], dtype=np.float32)\n",
        "        test_queries = np.array(f[\"test\"], dtype=np.float32)\n",
        "        ground_truth = np.array(f[\"neighbors\"], dtype=np.int64)[:, 0]\n",
        "    print(\"Dataset loaded.\")\n",
        "    return train_data, test_queries, ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uxlEyIxwPPFW"
      },
      "outputs": [],
      "source": [
        "def evaluate_hnsw(train_data, test_queries, ground_truth, M=32, efSearch_vals=[10, 50, 100, 200]):\n",
        "    d = train_data.shape[1]\n",
        "    index = faiss.IndexHNSWFlat(d, M, faiss.METRIC_L2)\n",
        "    index.hnsw.efConstruction = 200\n",
        "    index.add(train_data)\n",
        "\n",
        "    results = []\n",
        "    for ef in efSearch_vals:\n",
        "        print(\"Testing ef value:\", ef)\n",
        "        index.hnsw.efSearch = ef\n",
        "        start_time = time.time()\n",
        "        _, indices = index.search(test_queries, 1)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        recall = np.mean(indices[:, 0] == ground_truth)\n",
        "        qps = len(test_queries) / elapsed_time\n",
        "        results.append((ef, recall, qps, 0))\n",
        "        print(\"Took:\", elapsed_time, \"seconds\")\n",
        "\n",
        "    print(\"HNSW evaluated.\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_scann(train_data, test_queries, ground_truth, num_neighbors=1, num_search_trees=30, num_leaves=1000, num_leaves_to_search_vals=[10, 50, 100, 200], quantize=True):\n",
        "    train_data = train_data.astype(np.float32)\n",
        "    test_queries = test_queries.astype(np.float32)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for num_leaves_to_search in num_leaves_to_search_vals:\n",
        "        print(\"Building index\")\n",
        "        index = scann.scann_ops_pybind.builder(train_data, num_neighbors, \"dot_product\") \\\n",
        "        .tree(num_leaves=num_leaves, num_leaves_to_search=num_leaves_to_search, training_sample_size=len(train_data)) \\\n",
        "        .score_ah(2, anisotropic_quantization_threshold=0.2).reorder(100).build()\n",
        "\n",
        "        print(\"Testing num_leaves_to_search:\", num_leaves_to_search)\n",
        "        start_time = time.time()\n",
        "        indices = []\n",
        "        for query in test_queries:\n",
        "            i, _ = index.search(query, 1)\n",
        "            indices.append(i)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(\"Took:\", elapsed_time, \"seconds\")\n",
        "\n",
        "        indices = np.array(indices)\n",
        "        recall = np.mean(indices[:, 0] == ground_truth)\n",
        "        print(\"Recall:\", recall)\n",
        "        qps = len(test_queries) / elapsed_time\n",
        "        print(\"QPS:\", qps)\n",
        "\n",
        "        results.append((num_leaves_to_search, recall, qps, 0))\n",
        "\n",
        "    print(\"ScaNN evaluated.\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "PYj3zK93nQ90"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0eQc3IuVPPFW"
      },
      "outputs": [],
      "source": [
        "def evaluate_lsh(train_data, test_queries, ground_truth, nbits_vals=[32, 64, 512, 768]):\n",
        "    d = train_data.shape[1]\n",
        "    results = []\n",
        "\n",
        "    for nbits in nbits_vals:\n",
        "        index = faiss.IndexLSH(d, nbits)\n",
        "        index.train(train_data)\n",
        "        index.add(train_data)\n",
        "\n",
        "        start_time = time.time()\n",
        "        _, indices = index.search(test_queries, 1)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        recall = np.mean(indices[:, 0] == ground_truth)\n",
        "        qps = len(test_queries) / elapsed_time\n",
        "        results.append((nbits, recall, qps, 0))\n",
        "\n",
        "    print(\"LSH evaluated.\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fiass(train_data, test_queries, ground_truth, index_type=\"ivfflat\", batches=[1, 200, 500, 1000, 5000, 10000]):\n",
        "    results = []\n",
        "    total = train_data.shape[0]\n",
        "    for batch_size in batches:\n",
        "        dim = train_data.shape[1]\n",
        "\n",
        "        nlist = 100\n",
        "        m = 8\n",
        "        n_bit = 4   # 4 specifies that each sub-vector is encoded as 4 bits\n",
        "        bbs = 64    # build block size ( bbs % 32 == 0 ) for PQ\n",
        "        quantizer = faiss.IndexFlatL2(dim)\n",
        "        if index_type == \"ivfflat\":\n",
        "            index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_L2)\n",
        "        elif index_type == \"ivfpq\":\n",
        "            index = faiss.IndexIVFPQ(quantizer, dim, nlist, m, 8)\n",
        "        elif index_type == \"pqfastscan\":\n",
        "            index = faiss.IndexPQFastScan(dim, m, n_bit, faiss.METRIC_L2, bbs)\n",
        "        else:\n",
        "          index = quantizer\n",
        "\n",
        "        print(\"Building Index\")\n",
        "        batch_len = total // batch_size\n",
        "        start_time = time.time()\n",
        "        for i in range(batch_size):\n",
        "            start = i * batch_len\n",
        "            end = (i + 1) * batch_len if i != batch_size - 1 else total\n",
        "            index.train(train_data[start:end])\n",
        "            index.add(train_data[start:end])\n",
        "        build_time = time.time() - start_time\n",
        "        print(\"Build time:\", build_time)\n",
        "\n",
        "        print(\"Testing Search\")\n",
        "        start_time = time.time()\n",
        "        distances, indices = index.search(test_queries, 1)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        recall = np.mean(indices[:, 0] == ground_truth)\n",
        "        print(\"Recall:\", recall)\n",
        "        qps = len(test_queries) / elapsed_time\n",
        "        print(\"QPS:\", qps)\n",
        "        results.append((batch_size, recall, qps, build_time, \"batch_size\"))\n",
        "    return results"
      ],
      "metadata": {
        "id": "oF1ZzrF3Wv4N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fiass_percent(train_data, test_queries, ground_truth, index_type=\"ivfflat\", percents=[.50, .60, .70, .80, .90, 1.00]):\n",
        "    results = []\n",
        "    total = train_data.shape[0]\n",
        "    for percent in percents:\n",
        "        dim = train_data.shape[1]\n",
        "\n",
        "        nlist = 100\n",
        "        m = 8\n",
        "        n_bit = 4   # 4 specifies that each sub-vector is encoded as 4 bits\n",
        "        bbs = 64    # build block size ( bbs % 32 == 0 ) for PQ\n",
        "        quantizer = faiss.IndexFlatL2(dim)\n",
        "        if index_type == \"ivfflat\":\n",
        "            index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_L2)\n",
        "        elif index_type == \"ivfpq\":\n",
        "            index = faiss.IndexIVFPQ(quantizer, dim, nlist, m, 8)\n",
        "        elif index_type == \"pqfastscan\":\n",
        "            index = faiss.IndexPQFastScan(dim, m, n_bit, faiss.METRIC_L2, bbs)\n",
        "        else:\n",
        "          index = quantizer\n",
        "\n",
        "        print(\"Building Index\")\n",
        "        start_time = time.time()\n",
        "        break_point = int(total * percent)\n",
        "        print(break_point)\n",
        "        index.train(train_data[0:break_point])\n",
        "        index.add(train_data)\n",
        "        build_time = time.time() - start_time\n",
        "        print(\"Build time:\", build_time)\n",
        "\n",
        "        print(\"Testing Search\")\n",
        "        start_time = time.time()\n",
        "        distances, indices = index.search(test_queries, 1)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        recall = np.mean(indices[:, 0] == ground_truth)\n",
        "        print(\"Recall:\", recall)\n",
        "        qps = len(test_queries) / elapsed_time\n",
        "        print(\"QPS:\", qps)\n",
        "        results.append((percent, recall, qps, build_time, \"batch_size\"))\n",
        "    return results"
      ],
      "metadata": {
        "id": "i7AiHj3AIayX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lusnj10jPPFW"
      },
      "outputs": [],
      "source": [
        "def plot_results(results):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    for result in results:\n",
        "        for metric, recall, qps, build_time, label in result:\n",
        "            plt.scatter(qps, recall, label=f'{label}={metric}', marker='o')\n",
        "    plt.xlabel(\"Queries Per Second (QPS)\")\n",
        "    plt.ylabel(\"1-Recall@1\")\n",
        "    plt.title(\"QPS vs Recall\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    for result in results:\n",
        "        for metric, recall, qps, build_time, label in result:\n",
        "            plt.scatter(build_time, recall, label=f'{label}={metric}', marker='o')\n",
        "    plt.xlabel(\"Build Time (second)\")\n",
        "    plt.ylabel(\"1-Recall@1\")\n",
        "    plt.title(\"Build Time vs Recall\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_sift1m(SIFT1M_URL, SIFT1M_FILENAME)\n",
        "train_data, test_queries, ground_truth = load_sift1m(SIFT1M_FILENAME)\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(train_data)\n",
        "print(\"Test queries shape:\", test_queries.shape)\n",
        "print(test_queries)\n",
        "print(\"Ground truth shape:\", ground_truth.shape)\n",
        "print(ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6EUdmziMDY",
        "outputId": "603e550d-8269-4ae5-ba2d-acf049e09982"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIFT1M dataset already exists.\n",
            "<HDF5 file \"sift-128-euclidean.hdf5\" (mode r)>\n",
            "Dataset loaded.\n",
            "Train data shape: (1000000, 128)\n",
            "[[  0.  16.  35. ...  25.  23.   1.]\n",
            " [ 14.  35.  19. ...  11.  21.  33.]\n",
            " [  0.   1.   5. ...   4.  23.  10.]\n",
            " ...\n",
            " [ 30.  12.  12. ...  50.  10.   0.]\n",
            " [  0.   5.  12. ...   1.   2.  13.]\n",
            " [114.  31.   0. ...  25.  16.   0.]]\n",
            "Test queries shape: (10000, 128)\n",
            "[[  1.   3.  11. ...  42.  48.  11.]\n",
            " [ 40.  25.  11. ...   3.  19.  13.]\n",
            " [ 28.   4.   3. ...   2.  54.  47.]\n",
            " ...\n",
            " [  0.  15.  64. ...   3.  62. 118.]\n",
            " [131.   2.   0. ...   7.   0.   0.]\n",
            " [ 23.   0.   0. ...  79.  16.   4.]]\n",
            "Ground truth shape: (10000,)\n",
            "[932085 413247 669835 ... 123855 755327 874343]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hnsw_results = evaluate_hnsw(train_data, test_queries, ground_truth)\n",
        "print(hnsw_results)"
      ],
      "metadata": {
        "id": "wYfyY2zyUev3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4171b4af-78ec-425a-bccd-a2c6eab98dde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing ef value: 10\n",
            "Took: 1.0034310817718506 seconds\n",
            "Testing ef value: 50\n",
            "Took: 2.15854811668396 seconds\n",
            "Testing ef value: 100\n",
            "Took: 3.562847375869751 seconds\n",
            "Testing ef value: 200\n",
            "Took: 8.163212299346924 seconds\n",
            "HNSW evaluated.\n",
            "[(10, np.float64(0.854), 9965.806502965883, 0), (50, np.float64(0.9783), 4632.743612573419, 0), (100, np.float64(0.9906), 2806.7438610273985, 0), (200, np.float64(0.9929), 1225.0079543809027, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scann_results = evaluate_scann(train_data, test_queries, ground_truth)\n",
        "print(scann_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv94lDT6aGJ0",
        "outputId": "c3195669-bca7-43d0-ed93-ae4f57d7c57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fiass_results = eval_fiass(train_data, test_queries, ground_truth, index_type=\"ivfpq\", batches=[1, 10, 20, 50, 100])\n",
        "fiass_results = eval_fiass(train_data, test_queries, ground_truth, batches=[1, 10, 20, 50, 100])\n",
        "print(fiass_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVBGq4trZDME",
        "outputId": "d5789a66-eaa1-4167-ce07-b5185906da59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fiass_results_percent = eval_fiass_percent(train_data, test_queries, ground_truth)\n",
        "print(fiass_results_percent)"
      ],
      "metadata": {
        "id": "i6zUgfukK6j5",
        "outputId": "f1c7dbc8-dee5-49d5-ce85-bf5dc1e0c443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Index\n",
            "500000\n",
            "Build time: 1.6443662643432617\n",
            "Testing Search\n",
            "Recall: 0.6138\n",
            "QPS: 1831.3078996171953\n",
            "Building Index\n",
            "600000\n",
            "Build time: 1.7050743103027344\n",
            "Testing Search\n",
            "Recall: 0.6138\n",
            "QPS: 2086.423194648479\n",
            "Building Index\n",
            "700000\n",
            "Build time: 1.5279006958007812\n",
            "Testing Search\n",
            "Recall: 0.6113\n",
            "QPS: 1864.5663645938375\n",
            "Building Index\n",
            "800000\n",
            "Build time: 1.635122537612915\n",
            "Testing Search\n",
            "Recall: 0.6131\n",
            "QPS: 2206.0716010327287\n",
            "Building Index\n",
            "900000\n",
            "Build time: 1.639585018157959\n",
            "Testing Search\n",
            "Recall: 0.6054\n",
            "QPS: 1774.27742247564\n",
            "Building Index\n",
            "1000000\n",
            "Build time: 1.6969890594482422\n",
            "Testing Search\n",
            "Recall: 0.6144\n",
            "QPS: 2179.210837862982\n",
            "[(0.5, np.float64(0.6138), 1831.3078996171953, 1.6443662643432617, 'batch_size'), (0.6, np.float64(0.6138), 2086.423194648479, 1.7050743103027344, 'batch_size'), (0.7, np.float64(0.6113), 1864.5663645938375, 1.5279006958007812, 'batch_size'), (0.8, np.float64(0.6131), 2206.0716010327287, 1.635122537612915, 'batch_size'), (0.9, np.float64(0.6054), 1774.27742247564, 1.639585018157959, 'batch_size'), (1.0, np.float64(0.6144), 2179.210837862982, 1.6969890594482422, 'batch_size')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ground_truth)\n",
        "plot_results([fiass_results_percent])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "826ead96-861a-451b-b3c0-d6cd8c96f305",
        "id": "EJzeG_Emsl18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bd99dd898fcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiass_results_percent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_results' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}